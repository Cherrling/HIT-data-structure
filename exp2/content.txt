Abstract-As the main means of communication for deaf people, sign language has a special grammatical order, so it is meaningful and valuable to develop a real-time translation system for sign language. In the research process, we added a TSM module to the lightweight neural network model for the large Chinese continuous sign language dataset . It effectively improves the network performance with high accuracy and fast recognition speed. At the same time, we improve the Bert-Base-Chinese model to divide Chinese sentences into words and mapping the natural word order to the statute sign language order, and finally use the corresponding word videos in the isolated sign language dataset to generate the sentence video, so as to achieve the function of text-to-sign language translation. In the last of our research we built a system with sign language recognition and translation functions, and conducted performance tests on the complete dataset. The sign language video recognition accuracy reached about 99.3% with a time of about 0.05 seconds, and the sign language generation video time was about 1.3 seconds. The sign language system has good performance performance and is feasible.While able-bodied people can use verbal language to communicate easily, people with hearing impairment (deaf or aphasic people, etc.) need to communicate their thoughts through sign language. There are about 20.57 million deaf people in China, accounting for 1.67% of the total Chinese population, including about 800,000 children under the age of 7. They cannot communicate through language as normal people do, but communicate through sign language.Since most of the able-bodied people have not learned sign language, there are obstacles to promote sign language to make it applicable for communication in normal society. Sign language recognition and interpretation technology facilitates communication between hearing-impaired and able-bodied people. Sign language research should not only enable hearing people to read sign language, but also enable hearing people to understand what able-bodied people are saying. Sign language recognition and interpretation are the former, and sign language generation research is the latter. This interaction process is particularly important for people with hearing impairment. Therefore, the study of sign language recognition and interpretation and sign language generation has important theoretical and applied values as well as social significance. Sign language recognition technology and sign language generation technology can help daily communication, sign language interpretation and sign language education activities between deaf and able-bodied people, as well as improve the social skills and quality of life of deaf people, promote mutual understanding and communication between deaf and able-bodied people, and have practicality and applicability in the deaf community.The sign language recognition method based on wearable devices, i.e., using data gloves to directly obtain the hand shape, angle and relative position of fingers and other precise data of the granting person, so as to obtain the main characteristics of sign language and use recognition algorithms for recognition. This method does not require pre-processing of various information, and the acquired data is accurate and free from environmental interference, with the disadvantage of high cost and complexity of use.Computer vision-based sign language recognition method, i.e., the sign language gesture image or dynamic change information is obtained by camera or radar and input to the algorithm for sign language recognition. Compared with sign language recognition based on wearable devices, sign language personnel do not need wearable devices and the promotion is more advantageous. The disadvantage is that the exclusion of fuzzy frames, the pre-processing of data to exclude interfering information and the accuracy of information is not high. Table1 below shows the current status of sign language recognition research.This paper describes the importance of sign language in the communication between deaf and able-bodied people, and presents the research of Chinese sign language recognition algorithm and sign language generation algorithm based on deep learning and the implementation of the system.Deep learning is an artificial neural network technique that can learn and classify a large amount of data. In sign language recognition technology, deep learning technology can learn and classify a large amount of sign language images and video data to achieve recognition and translation of sign language. The research of Chinese sign language recognition technology and sign language generation technology and system based on deep learning can provide more accurate and efficient sign language recognition and translation services for communication between deaf and able-bodied people.In this paper, we combine different behavior recognition depth models, study the advantages and shortcomings of currently existing sign language recognition algorithms, delve into the latest research results of deep learning at home and abroad, consider the structural characteristics and structural advantages of existing convolutional neural network models, and explore the applicability, stability, and reliability of different structural convolutional neural networks in the field of sign language recognition.In the part of sign language recognition algorithm research, this paper firstly conducts video preprocessing, video feature extraction on the Chinese sign language continuous utterance SLR dataset constructed by the University of Science and Technology of China, and then adds the TSM module with better processing capability of temporally strongly correlated video to ResNet-50 and MobileNet models for training sign language video and analyzing experimental data; meanwhile, conducts Action-net, another type of behavior recognition model, is experimented to recognize sign language videos and analyze the experimental data; through experimental comparison, the performance and effect of the models are verified, and a sign language recognition algorithm suitable for CSL continuous utterance dataset is selected to realize the recognition and translation of sign language continuous utterances. In the part of sign language generation, the research aims to transform the spoken Chinese text into the sequence of sign language language through jieba splitting and then processed by Bert model, corresponding to the corresponding sign language vocabulary video, to complete the translation from text to video, and to verify the performance and effect of the model.